import numpy as np
from datetime import datetime
from joblib import Parallel, delayed
import multiprocessing as mp
import threading
import math


class Classify:
    def __init__(self, api_calls, loaded_model):
        self.tfidf_sum_good = 0
        self.tfidf_sum_mal = 0
        self.TFIDF = None
        self.w2v_sum_good = 0
        self.w2v_sum_mal = 0
        self.Word2Vec = None
        self.OneGram_sum_good = 0
        self.OneGram_sum_mal = 0
        self.OneGram = None
        self.TwoGrams_sum_good = 0
        self.TwoGrams_sum_mal = 0

        self.max_feat = None
        self.numeric = None
        self.ant_score = None
        self.max_bi = None
        self.Prediction = None
        self.api_calls = api_calls
        self.loaded_model = loaded_model
        threads_array = []
        number_of_threads =16
        self.start=datetime.now()
        for i in range(0, number_of_threads):
            
            if(i==(number_of_threads-1)):
                
                threads_array.append(threading.Thread(target=self.TFIDF_extraction, args=(loaded_model.malware_vectorizer, loaded_model.malware_vector,
                                                                                          loaded_model.goodware_vectorizer, loaded_model.goodware_vector, math.floor(i*len(api_calls)/number_of_threads), math.floor(((i+1)*len(api_calls)/(number_of_threads))-1))))
            else:     
                threads_array.append(threading.Thread(target=self.TFIDF_extraction, args=(loaded_model.malware_vectorizer, loaded_model.malware_vector,
                                                                                      loaded_model.goodware_vectorizer, loaded_model.goodware_vector, math.floor(i*len(api_calls)/number_of_threads), math.floor((i+1)*len(api_calls)/number_of_threads))))
            
            threads_array[i].start()
                          

        t2 = threading.Thread(target=self.w2v_extraction, args=(
            loaded_model.w2v_goodware, loaded_model.w2v_malware,))
        t3 = threading.Thread(target=self.onegram_extraction, args=(
            loaded_model.onegram_malware_vectorizer, loaded_model.onegram_goodware_vectorizer,))
        t4 = threading.Thread(target=self.twogram_extraction, args=(
            loaded_model.malware_max, loaded_model.goodware_max,))
        t5 = threading.Thread(target=self.ant_extraction, args=(
            loaded_model.goodware_ant, loaded_model.malware_ant,))
        t6 = threading.Thread(target=self.max_bi_gram_extraction, args=(
            loaded_model.twogram_malware_vectorizer, loaded_model.twogram_goodware_vectorizer,))
     
        """starting threads"""
       
        t2.start()
        t3.start()
        t4.start()
        t5.start()
        t6.start()

        """wait until threads are finished"""
        for i in range(0,number_of_threads):
            threads_array[i].join()
        t2.join()
        t3.join()
        t4.join()
        t5.join()
        t6.join()
       
        self.Predict()

    def TFIDF_extraction(self, mal_vectorizer, mal_vector, good_vectorizer, good_vector, start, end):
        
        
        for i in range(start, end):

            temp = self.api_calls[i].lower() + " " + \
                self.api_calls[i + 1].lower()

            if temp in mal_vectorizer.vocabulary_.keys():
                c = mal_vectorizer.vocabulary_[temp]
                y = mal_vector[:, c].todense()
                self.tfidf_sum_mal += y.sum() / len(y)
            if temp in good_vectorizer.vocabulary_.keys():
                c = good_vectorizer.vocabulary_[temp]
                y = good_vector[:, c].todense()
                self.tfidf_sum_good += y.sum() / len(y)

    def w2v_extraction(self, w2v_goodware, w2v_malware):

        sum_mal = 0
        sum_good = 0

        for i in range(len(self.api_calls) - 1):

            if self.api_calls[i].lower() in w2v_goodware.wv.key_to_index and self.api_calls[i + 1].lower() in w2v_goodware.wv.key_to_index:
                frequency = w2v_goodware.wv.similarity(
                    self.api_calls[i].lower(), self.api_calls[i + 1].lower())

                sum_good += frequency
            if self.api_calls[i].lower() in w2v_malware.wv.key_to_index and self.api_calls[i + 1].lower() in w2v_malware.wv.key_to_index:
                frequency2 = w2v_malware.wv.similarity(
                    self.api_calls[i].lower(), self.api_calls[i + 1].lower())

                sum_mal += frequency2

        self.w2v_sum_good = sum_good
        self.w2v_sum_mal = sum_mal
        if sum_good > sum_mal:
            self.Word2Vec = 0
        elif sum_mal > sum_good:
            self.Word2Vec = 1
        else:
            self.Word2Vec = 2

    def onegram_extraction(self, mal_vectorizer, good_vectorizer):

        sum_mal = 0
        sum_good = 0

        for i in range(len(self.api_calls)):
            temp = self.api_calls[i].lower()

            if temp in good_vectorizer.vocabulary_.keys():
                sum_good += 1

            if temp in mal_vectorizer.vocabulary_.keys():
                sum_mal += 1
        self.OneGram_sum_good = sum_good
        self.OneGram_sum_mal = sum_mal

        if sum_good > sum_mal:
            self.OneGram = 0
        elif sum_mal > sum_good:
            self.OneGram = 1
        else:
            self.OneGram = 2

    def twogram_extraction(self, mal_vectorizer, good_vectorizer):

        sum_mal = 0
        sum_good = 0
        for i in range(len(self.api_calls) - 1):
            temp = self.api_calls[i].lower() + " " + \
                self.api_calls[i + 1].lower()
            if temp in good_vectorizer.vocabulary_.keys():
                sum_good += 1
            if temp in mal_vectorizer.vocabulary_.keys():
                sum_mal += 1
        self.TwoGrams_sum_good = sum_good
        self.TwoGrams_sum_mal = sum_mal

        if sum_good > sum_mal:
            self.max_feat = 0
        elif sum_mal > sum_good:
            self.max_feat = 1
        else:
            self.max_feat = 2

    def ant_extraction(self, good_map, mal_map):

        sum_mal = 0
        sum_good = 0

        for i in range(len(self.api_calls) - 1):
            if mal_map.get(self.api_calls[i].lower(), self.api_calls[i + 1].lower()) is not None:
                sum_mal += 1
            if good_map.get(self.api_calls[i].lower(), self.api_calls[i + 1].lower()) is not None:
                sum_good += 1
        if sum_good > sum_mal:
            self.ant_score = 0
        elif sum_mal > sum_good:
            self.ant_score = 1
        else:
            self.ant_score = 2

    def max_bi_gram_extraction(self, mal_vectorizer, good_vectorizer):

        sum_mal = 0
        sum_good = 0
        for i in range(len(self.api_calls) - 1):
            temp = self.api_calls[i].lower() + " " + \
                self.api_calls[i + 1].lower()
            if temp in good_vectorizer.vocabulary_.keys():
                sum_good += 1
            if temp in mal_vectorizer.vocabulary_.keys():
                sum_mal += 1
        if sum_good > sum_mal:
            self.max_bi = 0
        elif sum_mal > sum_good:
            self.max_bi = 1
        else:
            self.max_bi = 2

    def Predict(self):
        print(datetime.now()-self.start)
        """Creates the array of features"""

        if self.tfidf_sum_good > self.tfidf_sum_mal:
            self.TFIDF = 0
        elif self.tfidf_sum_mal > self.tfidf_sum_good:
            self.TFIDF = 1
        else:
            self.TFIDF = 2

        X_predict = [
            [self.tfidf_sum_mal, self.tfidf_sum_good, self.w2v_sum_good, self.w2v_sum_mal, self.OneGram_sum_good,
             self.OneGram_sum_mal, self.TwoGrams_sum_good, self.TwoGrams_sum_mal, self.ant_score, self.max_bi,
             self.TFIDF, self.Word2Vec, self.OneGram, self.max_feat]]

        X_predict = np.array(X_predict)
        print(X_predict)
        """Standard Scaler to keep the values in the same range"""
        sc = self.loaded_model.sc
        X_predict = sc.transform(X_predict)
        """Prediction"""
        y_pred = self.loaded_model.model.predict(X_predict)
        if y_pred == 1:
            self.Prediction = "Malicious File"
        elif y_pred == 0:
            self.Prediction = "Normal File"
