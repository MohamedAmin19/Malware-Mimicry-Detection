{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789f7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import callbacks\n",
    "import keras_tuner as kt\n",
    "import pydot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1713c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('braz-mal14.csv')\n",
    "dataset.head()\n",
    "#X = dataset.drop(['stab', 'stabf'], axis=1)\n",
    "X = dataset.drop(['label'], axis = 1)\n",
    "y = dataset['label']\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X['ImportedSymbols']=label_encoder.fit_transform(X['ImportedSymbols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aca7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle =True, test_size=0.2, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802b5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_model = Sequential(\n",
    "#     [\n",
    "#         Dense(24 ,input_dim = 12, activation='relu'),\n",
    "#         Dense(24 , activation='relu'),\n",
    "#         Dense(24 , activation='relu'),\n",
    "#         Dense(12 , activation='relu'),\n",
    "#         Dense(1 , activation='sigmoid')\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# mlp_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239acee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=150, # n epochs before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# mlp_model.fit(X_train,y_train,epochs = 150, callbacks=[early_stopping],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31426177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# y_pred = mlp_model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5)\n",
    "\n",
    "# report = classification_report(y_test,y_pred, output_dict = True)\n",
    "# cr = pd.DataFrame(report).transpose()\n",
    "# print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aefd33a",
   "metadata": {},
   "source": [
    "# Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ee5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_units = hp.Int('units', min_value=12, max_value=192, step=12)\n",
    "    hp_dropout = hp.Choice('dropout', values=[0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    model = Sequential([\n",
    "    Dense(10 ,input_dim = 11, activation='relu'),\n",
    "        Dense(10 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(10 , activation='relu'),\n",
    "        Dense(10 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(10 , activation='relu'),\n",
    "        Dense(10 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(10 , activation='relu'),\n",
    "        Dense(10 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(2 , activation='relu'),\n",
    "        Dense(5 , activation='relu'),\n",
    "        Dense(1 , activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                loss=BinaryCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf17d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 174 Complete [00h 00m 02s]\n",
      "accuracy: 0.6706022024154663\n",
      "\n",
      "Best accuracy So Far: 0.8071691393852234\n",
      "Total elapsed time: 00h 08m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='accuracy',\n",
    "                     max_epochs=300,overwrite=True)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=300, validation_split=0.2, callbacks=[early_stopping])\n",
    "tuner.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b86d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.4949 - accuracy: 0.7239 - val_loss: 0.4170 - val_accuracy: 0.7899\n",
      "Epoch 2/300\n",
      "1027/1027 [==============================] - 1s 791us/step - loss: 0.4033 - accuracy: 0.7948 - val_loss: 0.3826 - val_accuracy: 0.8090\n",
      "Epoch 3/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.3795 - accuracy: 0.8074 - val_loss: 0.3853 - val_accuracy: 0.8150\n",
      "Epoch 4/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.3647 - accuracy: 0.8194 - val_loss: 0.3456 - val_accuracy: 0.8333\n",
      "Epoch 5/300\n",
      "1027/1027 [==============================] - 1s 793us/step - loss: 0.3631 - accuracy: 0.8213 - val_loss: 0.3437 - val_accuracy: 0.8353\n",
      "Epoch 6/300\n",
      "1027/1027 [==============================] - 1s 793us/step - loss: 0.3570 - accuracy: 0.8248 - val_loss: 0.3610 - val_accuracy: 0.8287\n",
      "Epoch 7/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.3554 - accuracy: 0.8250 - val_loss: 0.3403 - val_accuracy: 0.8333\n",
      "Epoch 8/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.3517 - accuracy: 0.8271 - val_loss: 0.3409 - val_accuracy: 0.8320\n",
      "Epoch 9/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.3513 - accuracy: 0.8279 - val_loss: 0.3456 - val_accuracy: 0.8342\n",
      "Epoch 10/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.3467 - accuracy: 0.8314 - val_loss: 0.3370 - val_accuracy: 0.8362\n",
      "Epoch 11/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.3445 - accuracy: 0.8322 - val_loss: 0.3319 - val_accuracy: 0.8447\n",
      "Epoch 12/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.3431 - accuracy: 0.8332 - val_loss: 0.3260 - val_accuracy: 0.8430\n",
      "Epoch 13/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.3407 - accuracy: 0.8339 - val_loss: 0.3301 - val_accuracy: 0.8437\n",
      "Epoch 14/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.3404 - accuracy: 0.8344 - val_loss: 0.3201 - val_accuracy: 0.8453\n",
      "Epoch 15/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.3370 - accuracy: 0.8365 - val_loss: 0.3194 - val_accuracy: 0.8477\n",
      "Epoch 16/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.3368 - accuracy: 0.8367 - val_loss: 0.3387 - val_accuracy: 0.8385\n",
      "Epoch 17/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.3339 - accuracy: 0.8407 - val_loss: 0.3144 - val_accuracy: 0.8547\n",
      "Epoch 18/300\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.3296 - accuracy: 0.8440 - val_loss: 0.3298 - val_accuracy: 0.8462\n",
      "Epoch 19/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.3327 - accuracy: 0.8388 - val_loss: 0.3148 - val_accuracy: 0.8474\n",
      "Epoch 20/300\n",
      "1027/1027 [==============================] - 1s 792us/step - loss: 0.3275 - accuracy: 0.8442 - val_loss: 0.3279 - val_accuracy: 0.8462\n",
      "Epoch 21/300\n",
      "1027/1027 [==============================] - 1s 792us/step - loss: 0.3242 - accuracy: 0.8457 - val_loss: 0.3248 - val_accuracy: 0.8477\n",
      "Epoch 22/300\n",
      "1027/1027 [==============================] - 1s 788us/step - loss: 0.3242 - accuracy: 0.8462 - val_loss: 0.3235 - val_accuracy: 0.8519\n",
      "Epoch 23/300\n",
      "1027/1027 [==============================] - 1s 792us/step - loss: 0.3239 - accuracy: 0.8448 - val_loss: 0.3174 - val_accuracy: 0.8487\n",
      "Epoch 24/300\n",
      "1027/1027 [==============================] - 1s 841us/step - loss: 0.3225 - accuracy: 0.8447 - val_loss: 0.3107 - val_accuracy: 0.8559\n",
      "Epoch 25/300\n",
      "1027/1027 [==============================] - 1s 863us/step - loss: 0.3169 - accuracy: 0.8466 - val_loss: 0.3075 - val_accuracy: 0.8539\n",
      "Epoch 26/300\n",
      "1027/1027 [==============================] - 1s 819us/step - loss: 0.3183 - accuracy: 0.8458 - val_loss: 0.3084 - val_accuracy: 0.8564\n",
      "Epoch 27/300\n",
      "1027/1027 [==============================] - 1s 787us/step - loss: 0.3157 - accuracy: 0.8468 - val_loss: 0.3052 - val_accuracy: 0.8564\n",
      "Epoch 28/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.3172 - accuracy: 0.8449 - val_loss: 0.3061 - val_accuracy: 0.8498\n",
      "Epoch 29/300\n",
      "1027/1027 [==============================] - 1s 812us/step - loss: 0.3225 - accuracy: 0.8405 - val_loss: 0.3033 - val_accuracy: 0.8556\n",
      "Epoch 30/300\n",
      "1027/1027 [==============================] - 1s 839us/step - loss: 0.3125 - accuracy: 0.8479 - val_loss: 0.2984 - val_accuracy: 0.8570\n",
      "Epoch 31/300\n",
      "1027/1027 [==============================] - 1s 830us/step - loss: 0.3159 - accuracy: 0.8453 - val_loss: 0.3269 - val_accuracy: 0.8424\n",
      "Epoch 32/300\n",
      "1027/1027 [==============================] - 1s 829us/step - loss: 0.3171 - accuracy: 0.8425 - val_loss: 0.2994 - val_accuracy: 0.8556\n",
      "Epoch 33/300\n",
      "1027/1027 [==============================] - 1s 827us/step - loss: 0.3141 - accuracy: 0.8462 - val_loss: 0.2993 - val_accuracy: 0.8576\n",
      "Epoch 34/300\n",
      "1027/1027 [==============================] - 1s 820us/step - loss: 0.3203 - accuracy: 0.8417 - val_loss: 0.3472 - val_accuracy: 0.8346\n",
      "Epoch 35/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.3107 - accuracy: 0.8475 - val_loss: 0.2969 - val_accuracy: 0.8539\n",
      "Epoch 36/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.3103 - accuracy: 0.8471 - val_loss: 0.3154 - val_accuracy: 0.8474\n",
      "Epoch 37/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.3092 - accuracy: 0.8481 - val_loss: 0.2983 - val_accuracy: 0.8565\n",
      "Epoch 38/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.3082 - accuracy: 0.8474 - val_loss: 0.3018 - val_accuracy: 0.8509\n",
      "Epoch 39/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.3063 - accuracy: 0.8478 - val_loss: 0.2995 - val_accuracy: 0.8542\n",
      "Epoch 40/300\n",
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.3113 - accuracy: 0.8452 - val_loss: 0.2990 - val_accuracy: 0.8548\n",
      "Epoch 41/300\n",
      "1027/1027 [==============================] - 1s 815us/step - loss: 0.3134 - accuracy: 0.8461 - val_loss: 0.3081 - val_accuracy: 0.8516\n",
      "Epoch 42/300\n",
      "1027/1027 [==============================] - 1s 785us/step - loss: 0.3129 - accuracy: 0.8460 - val_loss: 0.3142 - val_accuracy: 0.8499\n",
      "Epoch 43/300\n",
      "1027/1027 [==============================] - 1s 768us/step - loss: 0.3067 - accuracy: 0.8484 - val_loss: 0.2973 - val_accuracy: 0.8546\n",
      "Epoch 44/300\n",
      "1027/1027 [==============================] - 1s 781us/step - loss: 0.3119 - accuracy: 0.8460 - val_loss: 0.3073 - val_accuracy: 0.8482\n",
      "Epoch 45/300\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.3177 - accuracy: 0.8428 - val_loss: 0.2935 - val_accuracy: 0.8570\n",
      "Epoch 46/300\n",
      "1027/1027 [==============================] - 1s 791us/step - loss: 0.3071 - accuracy: 0.8482 - val_loss: 0.2913 - val_accuracy: 0.8572\n",
      "Epoch 47/300\n",
      "1027/1027 [==============================] - 1s 757us/step - loss: 0.3034 - accuracy: 0.8493 - val_loss: 0.2994 - val_accuracy: 0.8492\n",
      "Epoch 48/300\n",
      "1027/1027 [==============================] - 1s 761us/step - loss: 0.3048 - accuracy: 0.8486 - val_loss: 0.2901 - val_accuracy: 0.8576\n",
      "Epoch 49/300\n",
      "1027/1027 [==============================] - 1s 776us/step - loss: 0.3097 - accuracy: 0.8449 - val_loss: 0.2933 - val_accuracy: 0.8554\n",
      "Epoch 50/300\n",
      "1027/1027 [==============================] - 1s 788us/step - loss: 0.3053 - accuracy: 0.8480 - val_loss: 0.2993 - val_accuracy: 0.8522\n",
      "Epoch 51/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.3049 - accuracy: 0.8485 - val_loss: 0.2988 - val_accuracy: 0.8574\n",
      "Epoch 52/300\n",
      "1027/1027 [==============================] - 1s 830us/step - loss: 0.3032 - accuracy: 0.8502 - val_loss: 0.3050 - val_accuracy: 0.8492\n",
      "Epoch 53/300\n",
      "1027/1027 [==============================] - 1s 812us/step - loss: 0.3028 - accuracy: 0.8498 - val_loss: 0.3570 - val_accuracy: 0.8492\n",
      "Epoch 54/300\n",
      "1027/1027 [==============================] - 1s 811us/step - loss: 0.3016 - accuracy: 0.8495 - val_loss: 0.2989 - val_accuracy: 0.8543\n",
      "Epoch 55/300\n",
      "1027/1027 [==============================] - 1s 823us/step - loss: 0.3053 - accuracy: 0.8472 - val_loss: 0.2933 - val_accuracy: 0.8580\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - 1s 820us/step - loss: 0.3041 - accuracy: 0.8476 - val_loss: 0.3142 - val_accuracy: 0.8527\n",
      "Epoch 57/300\n",
      "1027/1027 [==============================] - 1s 819us/step - loss: 0.3016 - accuracy: 0.8504 - val_loss: 0.2926 - val_accuracy: 0.8547\n",
      "Epoch 58/300\n",
      "1027/1027 [==============================] - 1s 823us/step - loss: 0.3022 - accuracy: 0.8489 - val_loss: 0.2913 - val_accuracy: 0.8595\n",
      "Epoch 59/300\n",
      "1027/1027 [==============================] - 1s 823us/step - loss: 0.3081 - accuracy: 0.8475 - val_loss: 0.2961 - val_accuracy: 0.8582\n",
      "Epoch 60/300\n",
      "1027/1027 [==============================] - 1s 819us/step - loss: 0.3010 - accuracy: 0.8492 - val_loss: 0.3045 - val_accuracy: 0.8502\n",
      "Epoch 61/300\n",
      "1027/1027 [==============================] - 1s 819us/step - loss: 0.2970 - accuracy: 0.8509 - val_loss: 0.3030 - val_accuracy: 0.8535\n",
      "Epoch 62/300\n",
      "1027/1027 [==============================] - 1s 837us/step - loss: 0.3077 - accuracy: 0.8492 - val_loss: 0.2895 - val_accuracy: 0.8589\n",
      "Epoch 63/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2984 - accuracy: 0.8502 - val_loss: 0.3011 - val_accuracy: 0.8550\n",
      "Epoch 64/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2985 - accuracy: 0.8507 - val_loss: 0.2917 - val_accuracy: 0.8589\n",
      "Epoch 65/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2965 - accuracy: 0.8502 - val_loss: 0.2838 - val_accuracy: 0.8587\n",
      "Epoch 66/300\n",
      "1027/1027 [==============================] - 1s 820us/step - loss: 0.2976 - accuracy: 0.8503 - val_loss: 0.2840 - val_accuracy: 0.8588\n",
      "Epoch 67/300\n",
      "1027/1027 [==============================] - 1s 817us/step - loss: 0.2949 - accuracy: 0.8503 - val_loss: 0.2990 - val_accuracy: 0.8526\n",
      "Epoch 68/300\n",
      "1027/1027 [==============================] - 1s 818us/step - loss: 0.2958 - accuracy: 0.8503 - val_loss: 0.2882 - val_accuracy: 0.8580\n",
      "Epoch 69/300\n",
      "1027/1027 [==============================] - 1s 822us/step - loss: 0.2952 - accuracy: 0.8501 - val_loss: 0.2907 - val_accuracy: 0.8537\n",
      "Epoch 70/300\n",
      "1027/1027 [==============================] - 1s 818us/step - loss: 0.2954 - accuracy: 0.8500 - val_loss: 0.2906 - val_accuracy: 0.8549\n",
      "Epoch 71/300\n",
      "1027/1027 [==============================] - 1s 818us/step - loss: 0.2948 - accuracy: 0.8494 - val_loss: 0.2911 - val_accuracy: 0.8528\n",
      "Epoch 72/300\n",
      "1027/1027 [==============================] - 1s 821us/step - loss: 0.2973 - accuracy: 0.8495 - val_loss: 0.2814 - val_accuracy: 0.8584\n",
      "Epoch 73/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2928 - accuracy: 0.8512 - val_loss: 0.2872 - val_accuracy: 0.8527\n",
      "Epoch 74/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2934 - accuracy: 0.8511 - val_loss: 0.2966 - val_accuracy: 0.8547\n",
      "Epoch 75/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2955 - accuracy: 0.8486 - val_loss: 0.2833 - val_accuracy: 0.8589\n",
      "Epoch 76/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2940 - accuracy: 0.8500 - val_loss: 0.2910 - val_accuracy: 0.8511\n",
      "Epoch 77/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2918 - accuracy: 0.8514 - val_loss: 0.3056 - val_accuracy: 0.8497\n",
      "Epoch 78/300\n",
      "1027/1027 [==============================] - 1s 793us/step - loss: 0.2902 - accuracy: 0.8513 - val_loss: 0.2882 - val_accuracy: 0.8566\n",
      "Epoch 79/300\n",
      "1027/1027 [==============================] - 1s 786us/step - loss: 0.2958 - accuracy: 0.8489 - val_loss: 0.2912 - val_accuracy: 0.8561\n",
      "Epoch 80/300\n",
      "1027/1027 [==============================] - 1s 787us/step - loss: 0.2917 - accuracy: 0.8511 - val_loss: 0.2887 - val_accuracy: 0.8565\n",
      "Epoch 81/300\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.2915 - accuracy: 0.8514 - val_loss: 0.2813 - val_accuracy: 0.8588\n",
      "Epoch 82/300\n",
      "1027/1027 [==============================] - 1s 779us/step - loss: 0.2919 - accuracy: 0.8502 - val_loss: 0.2958 - val_accuracy: 0.8542\n",
      "Epoch 83/300\n",
      "1027/1027 [==============================] - 1s 792us/step - loss: 0.2904 - accuracy: 0.8506 - val_loss: 0.2849 - val_accuracy: 0.8588\n",
      "Epoch 84/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2909 - accuracy: 0.8508 - val_loss: 0.2855 - val_accuracy: 0.8587\n",
      "Epoch 85/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2920 - accuracy: 0.8501 - val_loss: 0.2863 - val_accuracy: 0.8527\n",
      "Epoch 86/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2915 - accuracy: 0.8510 - val_loss: 0.2790 - val_accuracy: 0.8588\n",
      "Epoch 87/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2893 - accuracy: 0.8507 - val_loss: 0.2819 - val_accuracy: 0.8593\n",
      "Epoch 88/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.3004 - accuracy: 0.8484 - val_loss: 0.2841 - val_accuracy: 0.8576\n",
      "Epoch 89/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.3097 - accuracy: 0.8438 - val_loss: 0.2828 - val_accuracy: 0.8578\n",
      "Epoch 90/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2898 - accuracy: 0.8511 - val_loss: 0.2928 - val_accuracy: 0.8587\n",
      "Epoch 91/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2924 - accuracy: 0.8506 - val_loss: 0.2813 - val_accuracy: 0.8587\n",
      "Epoch 92/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2888 - accuracy: 0.8514 - val_loss: 0.2850 - val_accuracy: 0.8571\n",
      "Epoch 93/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2894 - accuracy: 0.8511 - val_loss: 0.2897 - val_accuracy: 0.8584\n",
      "Epoch 94/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2911 - accuracy: 0.8502 - val_loss: 0.2835 - val_accuracy: 0.8598\n",
      "Epoch 95/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2880 - accuracy: 0.8519 - val_loss: 0.2813 - val_accuracy: 0.8575\n",
      "Epoch 96/300\n",
      "1027/1027 [==============================] - 1s 811us/step - loss: 0.2995 - accuracy: 0.8476 - val_loss: 0.2869 - val_accuracy: 0.8583\n",
      "Epoch 97/300\n",
      "1027/1027 [==============================] - 1s 815us/step - loss: 0.2906 - accuracy: 0.8500 - val_loss: 0.2922 - val_accuracy: 0.8580\n",
      "Epoch 98/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2890 - accuracy: 0.8516 - val_loss: 0.2874 - val_accuracy: 0.8554\n",
      "Epoch 99/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2886 - accuracy: 0.8514 - val_loss: 0.2945 - val_accuracy: 0.8561\n",
      "Epoch 100/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2903 - accuracy: 0.8505 - val_loss: 0.2807 - val_accuracy: 0.8594\n",
      "Epoch 101/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2882 - accuracy: 0.8504 - val_loss: 0.3145 - val_accuracy: 0.8454\n",
      "Epoch 102/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2938 - accuracy: 0.8498 - val_loss: 0.2806 - val_accuracy: 0.8587\n",
      "Epoch 103/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2878 - accuracy: 0.8516 - val_loss: 0.2814 - val_accuracy: 0.8569\n",
      "Epoch 104/300\n",
      "1027/1027 [==============================] - 1s 807us/step - loss: 0.2859 - accuracy: 0.8511 - val_loss: 0.2756 - val_accuracy: 0.8571\n",
      "Epoch 105/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2895 - accuracy: 0.8506 - val_loss: 0.2798 - val_accuracy: 0.8583\n",
      "Epoch 106/300\n",
      "1027/1027 [==============================] - 1s 807us/step - loss: 0.2880 - accuracy: 0.8510 - val_loss: 0.2834 - val_accuracy: 0.8589\n",
      "Epoch 107/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2876 - accuracy: 0.8505 - val_loss: 0.2807 - val_accuracy: 0.8603\n",
      "Epoch 108/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2869 - accuracy: 0.8519 - val_loss: 0.2867 - val_accuracy: 0.8572\n",
      "Epoch 109/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2879 - accuracy: 0.8529 - val_loss: 0.2818 - val_accuracy: 0.8565\n",
      "Epoch 110/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2894 - accuracy: 0.8504 - val_loss: 0.2917 - val_accuracy: 0.8567\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2896 - accuracy: 0.8502 - val_loss: 0.2811 - val_accuracy: 0.8589\n",
      "Epoch 112/300\n",
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.2906 - accuracy: 0.8495 - val_loss: 0.2911 - val_accuracy: 0.8576\n",
      "Epoch 113/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2858 - accuracy: 0.8523 - val_loss: 0.2783 - val_accuracy: 0.8592\n",
      "Epoch 114/300\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.2857 - accuracy: 0.8509 - val_loss: 0.2770 - val_accuracy: 0.8599\n",
      "Epoch 115/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2856 - accuracy: 0.8515 - val_loss: 0.2910 - val_accuracy: 0.8570\n",
      "Epoch 116/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2868 - accuracy: 0.8515 - val_loss: 0.3104 - val_accuracy: 0.8457\n",
      "Epoch 117/300\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.2867 - accuracy: 0.8516 - val_loss: 0.2803 - val_accuracy: 0.8603\n",
      "Epoch 118/300\n",
      "1027/1027 [==============================] - 1s 794us/step - loss: 0.2869 - accuracy: 0.8506 - val_loss: 0.3034 - val_accuracy: 0.8515\n",
      "Epoch 119/300\n",
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.2925 - accuracy: 0.8493 - val_loss: 0.2830 - val_accuracy: 0.8581\n",
      "Epoch 120/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2860 - accuracy: 0.8523 - val_loss: 0.2898 - val_accuracy: 0.8581\n",
      "Epoch 121/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2912 - accuracy: 0.8505 - val_loss: 0.2814 - val_accuracy: 0.8584\n",
      "Epoch 122/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2881 - accuracy: 0.8517 - val_loss: 0.2802 - val_accuracy: 0.8594\n",
      "Epoch 123/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2852 - accuracy: 0.8517 - val_loss: 0.2808 - val_accuracy: 0.8575\n",
      "Epoch 124/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2850 - accuracy: 0.8517 - val_loss: 0.2840 - val_accuracy: 0.8575\n",
      "Epoch 125/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2862 - accuracy: 0.8517 - val_loss: 0.2825 - val_accuracy: 0.8594\n",
      "Epoch 126/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2928 - accuracy: 0.8494 - val_loss: 0.2847 - val_accuracy: 0.8572\n",
      "Epoch 127/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2859 - accuracy: 0.8522 - val_loss: 0.2821 - val_accuracy: 0.8583\n",
      "Epoch 128/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2888 - accuracy: 0.8506 - val_loss: 0.2899 - val_accuracy: 0.8584\n",
      "Epoch 129/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2879 - accuracy: 0.8500 - val_loss: 0.2855 - val_accuracy: 0.8580\n",
      "Epoch 130/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2846 - accuracy: 0.8522 - val_loss: 0.2794 - val_accuracy: 0.8595\n",
      "Epoch 131/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2860 - accuracy: 0.8526 - val_loss: 0.2857 - val_accuracy: 0.8586\n",
      "Epoch 132/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2859 - accuracy: 0.8518 - val_loss: 0.2829 - val_accuracy: 0.8598\n",
      "Epoch 133/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2924 - accuracy: 0.8489 - val_loss: 0.2891 - val_accuracy: 0.8591\n",
      "Epoch 134/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2853 - accuracy: 0.8524 - val_loss: 0.2896 - val_accuracy: 0.8539\n",
      "Epoch 135/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2847 - accuracy: 0.8515 - val_loss: 0.2993 - val_accuracy: 0.8567\n",
      "Epoch 136/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2848 - accuracy: 0.8523 - val_loss: 0.2886 - val_accuracy: 0.8565\n",
      "Epoch 137/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2843 - accuracy: 0.8516 - val_loss: 0.2942 - val_accuracy: 0.8559\n",
      "Epoch 138/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2847 - accuracy: 0.8514 - val_loss: 0.2796 - val_accuracy: 0.8574\n",
      "Epoch 139/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2858 - accuracy: 0.8504 - val_loss: 0.2833 - val_accuracy: 0.8577\n",
      "Epoch 140/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2842 - accuracy: 0.8519 - val_loss: 0.2794 - val_accuracy: 0.8577\n",
      "Epoch 141/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2859 - accuracy: 0.8521 - val_loss: 0.2972 - val_accuracy: 0.8560\n",
      "Epoch 142/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2857 - accuracy: 0.8509 - val_loss: 0.2756 - val_accuracy: 0.8602\n",
      "Epoch 143/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2833 - accuracy: 0.8523 - val_loss: 0.2759 - val_accuracy: 0.8588\n",
      "Epoch 144/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2850 - accuracy: 0.8525 - val_loss: 0.2806 - val_accuracy: 0.8591\n",
      "Epoch 145/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2829 - accuracy: 0.8523 - val_loss: 0.2884 - val_accuracy: 0.8580\n",
      "Epoch 146/300\n",
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.2835 - accuracy: 0.8524 - val_loss: 0.2821 - val_accuracy: 0.8535\n",
      "Epoch 147/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2843 - accuracy: 0.8512 - val_loss: 0.2872 - val_accuracy: 0.8582\n",
      "Epoch 148/300\n",
      "1027/1027 [==============================] - 1s 791us/step - loss: 0.2837 - accuracy: 0.8526 - val_loss: 0.2834 - val_accuracy: 0.8565\n",
      "Epoch 149/300\n",
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.2845 - accuracy: 0.8518 - val_loss: 0.3014 - val_accuracy: 0.8575\n",
      "Epoch 150/300\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.2831 - accuracy: 0.8527 - val_loss: 0.2884 - val_accuracy: 0.8566\n",
      "Epoch 151/300\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.2864 - accuracy: 0.8503 - val_loss: 0.2861 - val_accuracy: 0.8544\n",
      "Epoch 152/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2827 - accuracy: 0.8521 - val_loss: 0.2893 - val_accuracy: 0.8559\n",
      "Epoch 153/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2838 - accuracy: 0.8523 - val_loss: 0.2807 - val_accuracy: 0.8591\n",
      "Epoch 154/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2861 - accuracy: 0.8512 - val_loss: 0.2809 - val_accuracy: 0.8584\n",
      "Epoch 155/300\n",
      "1027/1027 [==============================] - 1s 810us/step - loss: 0.2842 - accuracy: 0.8522 - val_loss: 0.2968 - val_accuracy: 0.8567\n",
      "Epoch 156/300\n",
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.2829 - accuracy: 0.8522 - val_loss: 0.2814 - val_accuracy: 0.8584\n",
      "Epoch 157/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2831 - accuracy: 0.8519 - val_loss: 0.2802 - val_accuracy: 0.8598\n",
      "Epoch 158/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2840 - accuracy: 0.8515 - val_loss: 0.2788 - val_accuracy: 0.8603\n",
      "Epoch 159/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2848 - accuracy: 0.8512 - val_loss: 0.2883 - val_accuracy: 0.8550\n",
      "Epoch 160/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2825 - accuracy: 0.8521 - val_loss: 0.2790 - val_accuracy: 0.8603\n",
      "Epoch 161/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2832 - accuracy: 0.8526 - val_loss: 0.2853 - val_accuracy: 0.8587\n",
      "Epoch 162/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2836 - accuracy: 0.8513 - val_loss: 0.2860 - val_accuracy: 0.8582\n",
      "Epoch 163/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2840 - accuracy: 0.8518 - val_loss: 0.2858 - val_accuracy: 0.8578\n",
      "Epoch 164/300\n",
      "1027/1027 [==============================] - 1s 793us/step - loss: 0.2827 - accuracy: 0.8517 - val_loss: 0.2946 - val_accuracy: 0.8558\n",
      "Epoch 165/300\n",
      "1027/1027 [==============================] - 1s 793us/step - loss: 0.2841 - accuracy: 0.8528 - val_loss: 0.2867 - val_accuracy: 0.8594\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.2842 - accuracy: 0.8524 - val_loss: 0.2775 - val_accuracy: 0.8603\n",
      "Epoch 167/300\n",
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.2834 - accuracy: 0.8523 - val_loss: 0.2941 - val_accuracy: 0.8554\n",
      "Epoch 168/300\n",
      "1027/1027 [==============================] - 1s 826us/step - loss: 0.2832 - accuracy: 0.8524 - val_loss: 0.2825 - val_accuracy: 0.8602\n",
      "Epoch 169/300\n",
      "1027/1027 [==============================] - 1s 869us/step - loss: 0.2832 - accuracy: 0.8512 - val_loss: 0.2799 - val_accuracy: 0.8598\n",
      "Epoch 170/300\n",
      "1027/1027 [==============================] - 1s 833us/step - loss: 0.2869 - accuracy: 0.8517 - val_loss: 0.2815 - val_accuracy: 0.8560\n",
      "Epoch 171/300\n",
      "1027/1027 [==============================] - 1s 813us/step - loss: 0.2866 - accuracy: 0.8472 - val_loss: 0.2799 - val_accuracy: 0.8588\n",
      "Epoch 172/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2823 - accuracy: 0.8530 - val_loss: 0.2884 - val_accuracy: 0.8594\n",
      "Epoch 173/300\n",
      "1027/1027 [==============================] - 1s 766us/step - loss: 0.2820 - accuracy: 0.8521 - val_loss: 0.2943 - val_accuracy: 0.8555\n",
      "Epoch 174/300\n",
      "1027/1027 [==============================] - 1s 779us/step - loss: 0.2831 - accuracy: 0.8517 - val_loss: 0.2792 - val_accuracy: 0.8577\n",
      "Epoch 175/300\n",
      "1027/1027 [==============================] - 1s 777us/step - loss: 0.2819 - accuracy: 0.8521 - val_loss: 0.2751 - val_accuracy: 0.8597\n",
      "Epoch 176/300\n",
      "1027/1027 [==============================] - 1s 792us/step - loss: 0.2948 - accuracy: 0.8485 - val_loss: 0.2879 - val_accuracy: 0.8581\n",
      "Epoch 177/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2836 - accuracy: 0.8513 - val_loss: 0.2770 - val_accuracy: 0.8600\n",
      "Epoch 178/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2812 - accuracy: 0.8519 - val_loss: 0.2825 - val_accuracy: 0.8605\n",
      "Epoch 179/300\n",
      "1027/1027 [==============================] - 1s 833us/step - loss: 0.2814 - accuracy: 0.8524 - val_loss: 0.2842 - val_accuracy: 0.8594\n",
      "Epoch 180/300\n",
      "1027/1027 [==============================] - 1s 841us/step - loss: 0.2827 - accuracy: 0.8524 - val_loss: 0.2746 - val_accuracy: 0.8598\n",
      "Epoch 181/300\n",
      "1027/1027 [==============================] - 1s 830us/step - loss: 0.2960 - accuracy: 0.8485 - val_loss: 0.2882 - val_accuracy: 0.8586\n",
      "Epoch 182/300\n",
      "1027/1027 [==============================] - 1s 824us/step - loss: 0.2827 - accuracy: 0.8518 - val_loss: 0.2761 - val_accuracy: 0.8591\n",
      "Epoch 183/300\n",
      "1027/1027 [==============================] - 1s 827us/step - loss: 0.2826 - accuracy: 0.8516 - val_loss: 0.2927 - val_accuracy: 0.8558\n",
      "Epoch 184/300\n",
      "1027/1027 [==============================] - 1s 823us/step - loss: 0.2848 - accuracy: 0.8517 - val_loss: 0.2756 - val_accuracy: 0.8605\n",
      "Epoch 185/300\n",
      "1027/1027 [==============================] - 1s 827us/step - loss: 0.2825 - accuracy: 0.8524 - val_loss: 0.2797 - val_accuracy: 0.8588\n",
      "Epoch 186/300\n",
      "1027/1027 [==============================] - 1s 826us/step - loss: 0.2833 - accuracy: 0.8512 - val_loss: 0.2887 - val_accuracy: 0.8547\n",
      "Epoch 187/300\n",
      "1027/1027 [==============================] - 1s 827us/step - loss: 0.2816 - accuracy: 0.8514 - val_loss: 0.2849 - val_accuracy: 0.8588\n",
      "Epoch 188/300\n",
      "1027/1027 [==============================] - 1s 826us/step - loss: 0.2824 - accuracy: 0.8520 - val_loss: 0.2772 - val_accuracy: 0.8603\n",
      "Epoch 189/300\n",
      "1027/1027 [==============================] - 1s 841us/step - loss: 0.2835 - accuracy: 0.8516 - val_loss: 0.2768 - val_accuracy: 0.8591\n",
      "Epoch 190/300\n",
      "1027/1027 [==============================] - 1s 815us/step - loss: 0.2810 - accuracy: 0.8527 - val_loss: 0.2915 - val_accuracy: 0.8569\n",
      "Epoch 191/300\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.2820 - accuracy: 0.8528 - val_loss: 0.2838 - val_accuracy: 0.8582\n",
      "Epoch 192/300\n",
      "1027/1027 [==============================] - 1s 814us/step - loss: 0.2829 - accuracy: 0.8521 - val_loss: 0.2776 - val_accuracy: 0.8597\n",
      "Epoch 193/300\n",
      "1027/1027 [==============================] - 1s 825us/step - loss: 0.2829 - accuracy: 0.8520 - val_loss: 0.2838 - val_accuracy: 0.8591\n",
      "Epoch 194/300\n",
      "1027/1027 [==============================] - 1s 828us/step - loss: 0.2828 - accuracy: 0.8518 - val_loss: 0.2817 - val_accuracy: 0.8593\n",
      "Epoch 195/300\n",
      "1027/1027 [==============================] - 1s 826us/step - loss: 0.2809 - accuracy: 0.8530 - val_loss: 0.2748 - val_accuracy: 0.8576\n",
      "Epoch 196/300\n",
      "1027/1027 [==============================] - 1s 826us/step - loss: 0.2845 - accuracy: 0.8517 - val_loss: 0.2741 - val_accuracy: 0.8602\n",
      "Epoch 197/300\n",
      "1027/1027 [==============================] - 1s 825us/step - loss: 0.2817 - accuracy: 0.8535 - val_loss: 0.2738 - val_accuracy: 0.8597\n",
      "Epoch 198/300\n",
      "1027/1027 [==============================] - 1s 823us/step - loss: 0.2826 - accuracy: 0.8510 - val_loss: 0.3002 - val_accuracy: 0.8541\n",
      "Epoch 199/300\n",
      "1027/1027 [==============================] - 1s 829us/step - loss: 0.2812 - accuracy: 0.8526 - val_loss: 0.2832 - val_accuracy: 0.8584\n",
      "Epoch 200/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2829 - accuracy: 0.8521 - val_loss: 0.2750 - val_accuracy: 0.8593\n",
      "Epoch 201/300\n",
      "1027/1027 [==============================] - 1s 812us/step - loss: 0.2808 - accuracy: 0.8522 - val_loss: 0.2742 - val_accuracy: 0.8594\n",
      "Epoch 202/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2827 - accuracy: 0.8516 - val_loss: 0.2862 - val_accuracy: 0.8606\n",
      "Epoch 203/300\n",
      "1027/1027 [==============================] - 1s 812us/step - loss: 0.2822 - accuracy: 0.8521 - val_loss: 0.2851 - val_accuracy: 0.8587\n",
      "Epoch 204/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2804 - accuracy: 0.8525 - val_loss: 0.2822 - val_accuracy: 0.8576\n",
      "Epoch 205/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2808 - accuracy: 0.8528 - val_loss: 0.2831 - val_accuracy: 0.8584\n",
      "Epoch 206/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2816 - accuracy: 0.8514 - val_loss: 0.2780 - val_accuracy: 0.8594\n",
      "Epoch 207/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2811 - accuracy: 0.8512 - val_loss: 0.2789 - val_accuracy: 0.8599\n",
      "Epoch 208/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2791 - accuracy: 0.8528 - val_loss: 0.2858 - val_accuracy: 0.8595\n",
      "Epoch 209/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2812 - accuracy: 0.8514 - val_loss: 0.2754 - val_accuracy: 0.8603\n",
      "Epoch 210/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2804 - accuracy: 0.8519 - val_loss: 0.2730 - val_accuracy: 0.8597\n",
      "Epoch 211/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2812 - accuracy: 0.8511 - val_loss: 0.2815 - val_accuracy: 0.8595\n",
      "Epoch 212/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2813 - accuracy: 0.8518 - val_loss: 0.2832 - val_accuracy: 0.8597\n",
      "Epoch 213/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2822 - accuracy: 0.8520 - val_loss: 0.2793 - val_accuracy: 0.8597\n",
      "Epoch 214/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2811 - accuracy: 0.8526 - val_loss: 0.2823 - val_accuracy: 0.8593\n",
      "Epoch 215/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2805 - accuracy: 0.8530 - val_loss: 0.2776 - val_accuracy: 0.8595\n",
      "Epoch 216/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2815 - accuracy: 0.8516 - val_loss: 0.3137 - val_accuracy: 0.8492\n",
      "Epoch 217/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2801 - accuracy: 0.8530 - val_loss: 0.2754 - val_accuracy: 0.8593\n",
      "Epoch 218/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2814 - accuracy: 0.8519 - val_loss: 0.2856 - val_accuracy: 0.8598\n",
      "Epoch 219/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2802 - accuracy: 0.8539 - val_loss: 0.2856 - val_accuracy: 0.8600\n",
      "Epoch 220/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2816 - accuracy: 0.8526 - val_loss: 0.2923 - val_accuracy: 0.8560\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2799 - accuracy: 0.8519 - val_loss: 0.2863 - val_accuracy: 0.8587\n",
      "Epoch 222/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2811 - accuracy: 0.8524 - val_loss: 0.3024 - val_accuracy: 0.8526\n",
      "Epoch 223/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2805 - accuracy: 0.8524 - val_loss: 0.2730 - val_accuracy: 0.8602\n",
      "Epoch 224/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2801 - accuracy: 0.8510 - val_loss: 0.3191 - val_accuracy: 0.8463\n",
      "Epoch 225/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2799 - accuracy: 0.8525 - val_loss: 0.2729 - val_accuracy: 0.8606\n",
      "Epoch 226/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2802 - accuracy: 0.8526 - val_loss: 0.2760 - val_accuracy: 0.8594\n",
      "Epoch 227/300\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.2802 - accuracy: 0.8524 - val_loss: 0.2770 - val_accuracy: 0.8583\n",
      "Epoch 228/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2802 - accuracy: 0.8526 - val_loss: 0.2736 - val_accuracy: 0.8595\n",
      "Epoch 229/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2808 - accuracy: 0.8528 - val_loss: 0.2870 - val_accuracy: 0.8580\n",
      "Epoch 230/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2804 - accuracy: 0.8516 - val_loss: 0.2903 - val_accuracy: 0.8584\n",
      "Epoch 231/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2786 - accuracy: 0.8530 - val_loss: 0.2819 - val_accuracy: 0.8582\n",
      "Epoch 232/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2815 - accuracy: 0.8522 - val_loss: 0.2842 - val_accuracy: 0.8582\n",
      "Epoch 233/300\n",
      "1027/1027 [==============================] - 1s 809us/step - loss: 0.2802 - accuracy: 0.8525 - val_loss: 0.2759 - val_accuracy: 0.8603\n",
      "Epoch 234/300\n",
      "1027/1027 [==============================] - 1s 807us/step - loss: 0.2798 - accuracy: 0.8529 - val_loss: 0.2797 - val_accuracy: 0.8606\n",
      "Epoch 235/300\n",
      "1027/1027 [==============================] - 1s 809us/step - loss: 0.2794 - accuracy: 0.8521 - val_loss: 0.2746 - val_accuracy: 0.8600\n",
      "Epoch 236/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2800 - accuracy: 0.8530 - val_loss: 0.2722 - val_accuracy: 0.8599\n",
      "Epoch 237/300\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.2812 - accuracy: 0.8528 - val_loss: 0.2800 - val_accuracy: 0.8604\n",
      "Epoch 238/300\n",
      "1027/1027 [==============================] - 1s 803us/step - loss: 0.2801 - accuracy: 0.8526 - val_loss: 0.2744 - val_accuracy: 0.8602\n",
      "Epoch 239/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2793 - accuracy: 0.8531 - val_loss: 0.2773 - val_accuracy: 0.8594\n",
      "Epoch 240/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2796 - accuracy: 0.8522 - val_loss: 0.2816 - val_accuracy: 0.8589\n",
      "Epoch 241/300\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.2795 - accuracy: 0.8528 - val_loss: 0.2811 - val_accuracy: 0.8582\n",
      "Epoch 242/300\n",
      "1027/1027 [==============================] - 1s 824us/step - loss: 0.2807 - accuracy: 0.8530 - val_loss: 0.2809 - val_accuracy: 0.8608\n",
      "Epoch 243/300\n",
      "1027/1027 [==============================] - 1s 838us/step - loss: 0.2796 - accuracy: 0.8529 - val_loss: 0.2765 - val_accuracy: 0.8580\n",
      "Epoch 244/300\n",
      "1027/1027 [==============================] - 1s 835us/step - loss: 0.2825 - accuracy: 0.8513 - val_loss: 0.2770 - val_accuracy: 0.8589\n",
      "Epoch 245/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2795 - accuracy: 0.8531 - val_loss: 0.2816 - val_accuracy: 0.8604\n",
      "Epoch 246/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2812 - accuracy: 0.8510 - val_loss: 0.2994 - val_accuracy: 0.8498\n",
      "Epoch 247/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2808 - accuracy: 0.8519 - val_loss: 0.2733 - val_accuracy: 0.8606\n",
      "Epoch 248/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2795 - accuracy: 0.8525 - val_loss: 0.2774 - val_accuracy: 0.8609\n",
      "Epoch 249/300\n",
      "1027/1027 [==============================] - 1s 809us/step - loss: 0.2803 - accuracy: 0.8520 - val_loss: 0.2831 - val_accuracy: 0.8572\n",
      "Epoch 250/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2799 - accuracy: 0.8526 - val_loss: 0.2930 - val_accuracy: 0.8588\n",
      "Epoch 251/300\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.2810 - accuracy: 0.8523 - val_loss: 0.3060 - val_accuracy: 0.8449\n",
      "Epoch 252/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2795 - accuracy: 0.8531 - val_loss: 0.2770 - val_accuracy: 0.8576\n",
      "Epoch 253/300\n",
      "1027/1027 [==============================] - 1s 807us/step - loss: 0.2787 - accuracy: 0.8520 - val_loss: 0.2781 - val_accuracy: 0.8583\n",
      "Epoch 254/300\n",
      "1027/1027 [==============================] - 1s 836us/step - loss: 0.2793 - accuracy: 0.8528 - val_loss: 0.2877 - val_accuracy: 0.8561\n",
      "Epoch 255/300\n",
      "1027/1027 [==============================] - 1s 849us/step - loss: 0.2801 - accuracy: 0.8524 - val_loss: 0.2797 - val_accuracy: 0.8567\n",
      "Epoch 256/300\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.2809 - accuracy: 0.8528 - val_loss: 0.2761 - val_accuracy: 0.8610\n",
      "Epoch 257/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2797 - accuracy: 0.8524 - val_loss: 0.2717 - val_accuracy: 0.8595\n",
      "Epoch 258/300\n",
      "1027/1027 [==============================] - 1s 813us/step - loss: 0.2803 - accuracy: 0.8514 - val_loss: 0.2739 - val_accuracy: 0.8594\n",
      "Epoch 259/300\n",
      "1027/1027 [==============================] - 1s 838us/step - loss: 0.2802 - accuracy: 0.8520 - val_loss: 0.2848 - val_accuracy: 0.8592\n",
      "Epoch 260/300\n",
      "1027/1027 [==============================] - 1s 831us/step - loss: 0.2788 - accuracy: 0.8518 - val_loss: 0.2849 - val_accuracy: 0.8597\n",
      "Epoch 261/300\n",
      "1027/1027 [==============================] - 1s 828us/step - loss: 0.2790 - accuracy: 0.8519 - val_loss: 0.2734 - val_accuracy: 0.8615\n",
      "Epoch 262/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2786 - accuracy: 0.8541 - val_loss: 0.2828 - val_accuracy: 0.8608\n",
      "Epoch 263/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2804 - accuracy: 0.8519 - val_loss: 0.2773 - val_accuracy: 0.8598\n",
      "Epoch 264/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2784 - accuracy: 0.8535 - val_loss: 0.2741 - val_accuracy: 0.8610\n",
      "Epoch 265/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2797 - accuracy: 0.8533 - val_loss: 0.2804 - val_accuracy: 0.8581\n",
      "Epoch 266/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2793 - accuracy: 0.8538 - val_loss: 0.2768 - val_accuracy: 0.8587\n",
      "Epoch 267/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2787 - accuracy: 0.8524 - val_loss: 0.2786 - val_accuracy: 0.8598\n",
      "Epoch 268/300\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.2788 - accuracy: 0.8532 - val_loss: 0.2883 - val_accuracy: 0.8565\n",
      "Epoch 269/300\n",
      "1027/1027 [==============================] - 1s 810us/step - loss: 0.2806 - accuracy: 0.8524 - val_loss: 0.2968 - val_accuracy: 0.8511\n",
      "Epoch 270/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2842 - accuracy: 0.8521 - val_loss: 0.3367 - val_accuracy: 0.8418\n",
      "Epoch 271/300\n",
      "1027/1027 [==============================] - 1s 802us/step - loss: 0.2898 - accuracy: 0.8501 - val_loss: 0.2905 - val_accuracy: 0.8553\n",
      "Epoch 272/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2780 - accuracy: 0.8539 - val_loss: 0.2772 - val_accuracy: 0.8599\n",
      "Epoch 273/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2799 - accuracy: 0.8522 - val_loss: 0.2815 - val_accuracy: 0.8583\n",
      "Epoch 274/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2791 - accuracy: 0.8534 - val_loss: 0.2787 - val_accuracy: 0.8587\n",
      "Epoch 275/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2784 - accuracy: 0.8520 - val_loss: 0.2891 - val_accuracy: 0.8553\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - 1s 796us/step - loss: 0.2793 - accuracy: 0.8517 - val_loss: 0.2786 - val_accuracy: 0.8561\n",
      "Epoch 277/300\n",
      "1027/1027 [==============================] - 1s 798us/step - loss: 0.2791 - accuracy: 0.8532 - val_loss: 0.2810 - val_accuracy: 0.8584\n",
      "Epoch 278/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2797 - accuracy: 0.8522 - val_loss: 0.2758 - val_accuracy: 0.8608\n",
      "Epoch 279/300\n",
      "1027/1027 [==============================] - 1s 800us/step - loss: 0.2787 - accuracy: 0.8533 - val_loss: 0.2793 - val_accuracy: 0.8606\n",
      "Epoch 280/300\n",
      "1027/1027 [==============================] - 1s 799us/step - loss: 0.2789 - accuracy: 0.8532 - val_loss: 0.3050 - val_accuracy: 0.8552\n",
      "Epoch 281/300\n",
      "1027/1027 [==============================] - 1s 797us/step - loss: 0.2771 - accuracy: 0.8524 - val_loss: 0.2811 - val_accuracy: 0.8600\n",
      "Epoch 282/300\n",
      "1027/1027 [==============================] - 1s 831us/step - loss: 0.2818 - accuracy: 0.8514 - val_loss: 0.2886 - val_accuracy: 0.8609\n",
      "Epoch 283/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2789 - accuracy: 0.8533 - val_loss: 0.2714 - val_accuracy: 0.8599\n",
      "Epoch 284/300\n",
      "1027/1027 [==============================] - 1s 811us/step - loss: 0.2792 - accuracy: 0.8525 - val_loss: 0.2848 - val_accuracy: 0.8577\n",
      "Epoch 285/300\n",
      "1027/1027 [==============================] - 1s 817us/step - loss: 0.2789 - accuracy: 0.8523 - val_loss: 0.2731 - val_accuracy: 0.8597\n",
      "Epoch 286/300\n",
      "1027/1027 [==============================] - 1s 819us/step - loss: 0.2799 - accuracy: 0.8524 - val_loss: 0.2726 - val_accuracy: 0.8615\n",
      "Epoch 287/300\n",
      "1027/1027 [==============================] - 1s 826us/step - loss: 0.2999 - accuracy: 0.8456 - val_loss: 0.2871 - val_accuracy: 0.8584\n",
      "Epoch 288/300\n",
      "1027/1027 [==============================] - 1s 824us/step - loss: 0.2787 - accuracy: 0.8518 - val_loss: 0.2850 - val_accuracy: 0.8574\n",
      "Epoch 289/300\n",
      "1027/1027 [==============================] - 1s 817us/step - loss: 0.2783 - accuracy: 0.8526 - val_loss: 0.2888 - val_accuracy: 0.8572\n",
      "Epoch 290/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2791 - accuracy: 0.8525 - val_loss: 0.2838 - val_accuracy: 0.8581\n",
      "Epoch 291/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2899 - accuracy: 0.8491 - val_loss: 0.2707 - val_accuracy: 0.8606\n",
      "Epoch 292/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2802 - accuracy: 0.8522 - val_loss: 0.2803 - val_accuracy: 0.8594\n",
      "Epoch 293/300\n",
      "1027/1027 [==============================] - 1s 804us/step - loss: 0.2795 - accuracy: 0.8517 - val_loss: 0.2932 - val_accuracy: 0.8513\n",
      "Epoch 294/300\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.2782 - accuracy: 0.8524 - val_loss: 0.2774 - val_accuracy: 0.8591\n",
      "Epoch 295/300\n",
      "1027/1027 [==============================] - 1s 806us/step - loss: 0.2764 - accuracy: 0.8539 - val_loss: 0.2719 - val_accuracy: 0.8604\n",
      "Epoch 296/300\n",
      "1027/1027 [==============================] - 1s 801us/step - loss: 0.2776 - accuracy: 0.8528 - val_loss: 0.2826 - val_accuracy: 0.8586\n",
      "Epoch 297/300\n",
      "1027/1027 [==============================] - 1s 794us/step - loss: 0.2791 - accuracy: 0.8524 - val_loss: 0.3060 - val_accuracy: 0.8465\n",
      "Epoch 298/300\n",
      "1027/1027 [==============================] - 1s 775us/step - loss: 0.2806 - accuracy: 0.8518 - val_loss: 0.2747 - val_accuracy: 0.8598\n",
      "Epoch 299/300\n",
      "1027/1027 [==============================] - 1s 771us/step - loss: 0.2784 - accuracy: 0.8526 - val_loss: 0.2800 - val_accuracy: 0.8597\n",
      "Epoch 300/300\n",
      "1027/1027 [==============================] - 1s 771us/step - loss: 0.2782 - accuracy: 0.8523 - val_loss: 0.2803 - val_accuracy: 0.8587\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "tuned_model = tuner.hypermodel.build(best_hps)\n",
    "history = tuned_model.fit(X_train, y_train, epochs=300, callbacks=[early_stopping], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b252ea4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 933\n",
      "Trainable params: 933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d3f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "0              0.694167  0.992257  0.816867   3358.000000\n",
      "1              0.995247  0.787616  0.879341   6912.000000\n",
      "accuracy       0.854528  0.854528  0.854528      0.854528\n",
      "macro avg      0.844707  0.889937  0.848104  10270.000000\n",
      "weighted avg   0.896802  0.854528  0.858914  10270.000000\n"
     ]
    }
   ],
   "source": [
    "y_pred = tuned_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "report = classification_report(y_test,y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa437c33",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_model() got an unexpected keyword argument 'show_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_656/3550387100.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m plot_model(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtuned_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tuned_model.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'LR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlayer_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_activations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_model() got an unexpected keyword argument 'show_dtype'"
     ]
    }
   ],
   "source": [
    "plot_model(\n",
    "    tuned_model, to_file='tuned_model.png', show_shapes=False, show_dtype=False,\n",
    "    show_layer_names=True, rankdir='LR', expand_nested=False, dpi=150,\n",
    "    layer_range=None, show_layer_activations=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac50b7d",
   "metadata": {},
   "source": [
    "# Droput Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e95b6aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1027/1027 [==============================] - 1s 895us/step - loss: 0.4474 - accuracy: 0.7519 - val_loss: 0.4002 - val_accuracy: 0.7813\n",
      "Epoch 2/150\n",
      "1027/1027 [==============================] - 1s 762us/step - loss: 0.4076 - accuracy: 0.7756 - val_loss: 0.3981 - val_accuracy: 0.7874\n",
      "Epoch 3/150\n",
      "1027/1027 [==============================] - 1s 765us/step - loss: 0.4005 - accuracy: 0.7814 - val_loss: 0.3993 - val_accuracy: 0.7865\n",
      "Epoch 4/150\n",
      "1027/1027 [==============================] - 1s 822us/step - loss: 0.3997 - accuracy: 0.7803 - val_loss: 0.3886 - val_accuracy: 0.7887\n",
      "Epoch 5/150\n",
      "1027/1027 [==============================] - 1s 757us/step - loss: 0.3971 - accuracy: 0.7825 - val_loss: 0.3940 - val_accuracy: 0.7874\n",
      "Epoch 6/150\n",
      "1027/1027 [==============================] - 1s 778us/step - loss: 0.3965 - accuracy: 0.7826 - val_loss: 0.3973 - val_accuracy: 0.7888\n",
      "Epoch 7/150\n",
      "1027/1027 [==============================] - 1s 821us/step - loss: 0.3954 - accuracy: 0.7840 - val_loss: 0.3930 - val_accuracy: 0.7825\n",
      "Epoch 8/150\n",
      "1027/1027 [==============================] - 1s 745us/step - loss: 0.3955 - accuracy: 0.7840 - val_loss: 0.3890 - val_accuracy: 0.7871\n",
      "Epoch 9/150\n",
      "1027/1027 [==============================] - 1s 753us/step - loss: 0.3935 - accuracy: 0.7863 - val_loss: 0.3846 - val_accuracy: 0.7943\n",
      "Epoch 10/150\n",
      "1027/1027 [==============================] - 1s 744us/step - loss: 0.3917 - accuracy: 0.7870 - val_loss: 0.3852 - val_accuracy: 0.7949\n",
      "Epoch 11/150\n",
      "1027/1027 [==============================] - 1s 750us/step - loss: 0.3910 - accuracy: 0.7899 - val_loss: 0.3860 - val_accuracy: 0.7927\n",
      "Epoch 12/150\n",
      "1027/1027 [==============================] - 1s 729us/step - loss: 0.3895 - accuracy: 0.7900 - val_loss: 0.3934 - val_accuracy: 0.7924\n",
      "Epoch 13/150\n",
      "1027/1027 [==============================] - 1s 752us/step - loss: 0.3892 - accuracy: 0.7927 - val_loss: 0.3825 - val_accuracy: 0.7965\n",
      "Epoch 14/150\n",
      "1027/1027 [==============================] - 1s 761us/step - loss: 0.3882 - accuracy: 0.7930 - val_loss: 0.3816 - val_accuracy: 0.7970\n",
      "Epoch 15/150\n",
      "1027/1027 [==============================] - 1s 764us/step - loss: 0.3861 - accuracy: 0.7941 - val_loss: 0.3797 - val_accuracy: 0.8042\n",
      "Epoch 16/150\n",
      "1027/1027 [==============================] - 1s 748us/step - loss: 0.3862 - accuracy: 0.7948 - val_loss: 0.3947 - val_accuracy: 0.7970\n",
      "Epoch 17/150\n",
      "1027/1027 [==============================] - 1s 756us/step - loss: 0.3857 - accuracy: 0.7963 - val_loss: 0.3830 - val_accuracy: 0.7993\n",
      "Epoch 18/150\n",
      "1027/1027 [==============================] - 1s 754us/step - loss: 0.3844 - accuracy: 0.7973 - val_loss: 0.3777 - val_accuracy: 0.8044\n",
      "Epoch 19/150\n",
      "1027/1027 [==============================] - 1s 758us/step - loss: 0.3838 - accuracy: 0.7975 - val_loss: 0.3794 - val_accuracy: 0.8039\n",
      "Epoch 20/150\n",
      "1027/1027 [==============================] - 1s 760us/step - loss: 0.3849 - accuracy: 0.7957 - val_loss: 0.3768 - val_accuracy: 0.8055\n",
      "Epoch 21/150\n",
      "1027/1027 [==============================] - 1s 743us/step - loss: 0.3831 - accuracy: 0.7975 - val_loss: 0.3759 - val_accuracy: 0.8062\n",
      "Epoch 22/150\n",
      "1027/1027 [==============================] - 1s 747us/step - loss: 0.3830 - accuracy: 0.7979 - val_loss: 0.3740 - val_accuracy: 0.8050\n",
      "Epoch 23/150\n",
      "1027/1027 [==============================] - 1s 741us/step - loss: 0.3831 - accuracy: 0.7978 - val_loss: 0.3881 - val_accuracy: 0.7947\n",
      "Epoch 24/150\n",
      "1027/1027 [==============================] - 1s 753us/step - loss: 0.3817 - accuracy: 0.7987 - val_loss: 0.3749 - val_accuracy: 0.8072\n",
      "Epoch 25/150\n",
      "1027/1027 [==============================] - 1s 749us/step - loss: 0.3811 - accuracy: 0.7995 - val_loss: 0.3967 - val_accuracy: 0.7995\n",
      "Epoch 26/150\n",
      "1027/1027 [==============================] - 1s 767us/step - loss: 0.3814 - accuracy: 0.7983 - val_loss: 0.3793 - val_accuracy: 0.8029\n",
      "Epoch 27/150\n",
      "1027/1027 [==============================] - 1s 763us/step - loss: 0.3805 - accuracy: 0.7984 - val_loss: 0.3819 - val_accuracy: 0.7993\n",
      "Epoch 28/150\n",
      "1027/1027 [==============================] - 1s 755us/step - loss: 0.3809 - accuracy: 0.7990 - val_loss: 0.3941 - val_accuracy: 0.8026\n",
      "Epoch 29/150\n",
      "1027/1027 [==============================] - 1s 754us/step - loss: 0.3812 - accuracy: 0.7995 - val_loss: 0.3737 - val_accuracy: 0.8028\n",
      "Epoch 30/150\n",
      "1027/1027 [==============================] - 1s 755us/step - loss: 0.3800 - accuracy: 0.7988 - val_loss: 0.3736 - val_accuracy: 0.8056\n",
      "Epoch 31/150\n",
      "1027/1027 [==============================] - 1s 760us/step - loss: 0.3800 - accuracy: 0.8003 - val_loss: 0.3726 - val_accuracy: 0.8061\n",
      "Epoch 32/150\n",
      "1027/1027 [==============================] - 1s 738us/step - loss: 0.3787 - accuracy: 0.8000 - val_loss: 0.3763 - val_accuracy: 0.8059\n",
      "Epoch 33/150\n",
      "1027/1027 [==============================] - 1s 728us/step - loss: 0.3800 - accuracy: 0.7985 - val_loss: 0.3722 - val_accuracy: 0.8070\n",
      "Epoch 34/150\n",
      "1027/1027 [==============================] - 1s 731us/step - loss: 0.3797 - accuracy: 0.7998 - val_loss: 0.3743 - val_accuracy: 0.8037\n",
      "Epoch 35/150\n",
      "1027/1027 [==============================] - 1s 738us/step - loss: 0.3795 - accuracy: 0.7999 - val_loss: 0.3793 - val_accuracy: 0.8076\n",
      "Epoch 36/150\n",
      "1027/1027 [==============================] - 1s 753us/step - loss: 0.3792 - accuracy: 0.7997 - val_loss: 0.3744 - val_accuracy: 0.8050\n",
      "Epoch 37/150\n",
      "1027/1027 [==============================] - 1s 746us/step - loss: 0.3786 - accuracy: 0.7998 - val_loss: 0.3715 - val_accuracy: 0.8064\n",
      "Epoch 38/150\n",
      "1027/1027 [==============================] - 1s 744us/step - loss: 0.3798 - accuracy: 0.7991 - val_loss: 0.3730 - val_accuracy: 0.8061\n",
      "Epoch 39/150\n",
      "1027/1027 [==============================] - 1s 748us/step - loss: 0.3789 - accuracy: 0.7995 - val_loss: 0.3759 - val_accuracy: 0.8045\n",
      "Epoch 40/150\n",
      "1027/1027 [==============================] - 1s 770us/step - loss: 0.3776 - accuracy: 0.8006 - val_loss: 0.3731 - val_accuracy: 0.8054\n",
      "Epoch 41/150\n",
      "1027/1027 [==============================] - 1s 749us/step - loss: 0.3772 - accuracy: 0.8005 - val_loss: 0.3769 - val_accuracy: 0.8061\n",
      "Epoch 42/150\n",
      "1027/1027 [==============================] - 1s 780us/step - loss: 0.3795 - accuracy: 0.8005 - val_loss: 0.3746 - val_accuracy: 0.8046\n",
      "Epoch 43/150\n",
      "1027/1027 [==============================] - 1s 760us/step - loss: 0.3779 - accuracy: 0.8001 - val_loss: 0.3733 - val_accuracy: 0.8054\n",
      "Epoch 44/150\n",
      "1027/1027 [==============================] - 1s 758us/step - loss: 0.3775 - accuracy: 0.8010 - val_loss: 0.3711 - val_accuracy: 0.8066\n",
      "Epoch 45/150\n",
      "1027/1027 [==============================] - 1s 746us/step - loss: 0.3768 - accuracy: 0.8003 - val_loss: 0.3774 - val_accuracy: 0.8062\n",
      "Epoch 46/150\n",
      "1027/1027 [==============================] - 1s 745us/step - loss: 0.3787 - accuracy: 0.7995 - val_loss: 0.3670 - val_accuracy: 0.8054\n",
      "Epoch 47/150\n",
      "1027/1027 [==============================] - 1s 750us/step - loss: 0.3773 - accuracy: 0.8014 - val_loss: 0.3742 - val_accuracy: 0.8068\n",
      "Epoch 48/150\n",
      "1027/1027 [==============================] - 1s 756us/step - loss: 0.3773 - accuracy: 0.8008 - val_loss: 0.3730 - val_accuracy: 0.8038\n",
      "Epoch 49/150\n",
      "1027/1027 [==============================] - 1s 759us/step - loss: 0.3764 - accuracy: 0.8013 - val_loss: 0.3717 - val_accuracy: 0.8065\n",
      "Epoch 50/150\n",
      "1027/1027 [==============================] - 1s 780us/step - loss: 0.3758 - accuracy: 0.8021 - val_loss: 0.3705 - val_accuracy: 0.8071\n",
      "Epoch 51/150\n",
      "1027/1027 [==============================] - 1s 784us/step - loss: 0.3773 - accuracy: 0.8019 - val_loss: 0.3722 - val_accuracy: 0.8072\n",
      "Epoch 52/150\n",
      "1027/1027 [==============================] - 1s 774us/step - loss: 0.3767 - accuracy: 0.8021 - val_loss: 0.3733 - val_accuracy: 0.8046\n",
      "Epoch 53/150\n",
      "1027/1027 [==============================] - 1s 805us/step - loss: 0.3757 - accuracy: 0.8019 - val_loss: 0.3721 - val_accuracy: 0.8066\n",
      "Epoch 54/150\n",
      "1027/1027 [==============================] - 1s 761us/step - loss: 0.3757 - accuracy: 0.8016 - val_loss: 0.3829 - val_accuracy: 0.8068\n",
      "Epoch 55/150\n",
      "1027/1027 [==============================] - 1s 763us/step - loss: 0.3768 - accuracy: 0.8005 - val_loss: 0.3808 - val_accuracy: 0.8045\n",
      "Epoch 56/150\n",
      "1027/1027 [==============================] - 1s 745us/step - loss: 0.3753 - accuracy: 0.8011 - val_loss: 0.3745 - val_accuracy: 0.8022\n",
      "Epoch 57/150\n",
      "1027/1027 [==============================] - 1s 747us/step - loss: 0.3755 - accuracy: 0.8012 - val_loss: 0.3755 - val_accuracy: 0.8081\n",
      "Epoch 58/150\n",
      "1027/1027 [==============================] - 1s 734us/step - loss: 0.3755 - accuracy: 0.8016 - val_loss: 0.3696 - val_accuracy: 0.8079\n",
      "Epoch 59/150\n",
      "1027/1027 [==============================] - 1s 767us/step - loss: 0.3790 - accuracy: 0.7982 - val_loss: 0.3702 - val_accuracy: 0.8051\n",
      "Epoch 60/150\n",
      "1027/1027 [==============================] - 1s 745us/step - loss: 0.3763 - accuracy: 0.8011 - val_loss: 0.3748 - val_accuracy: 0.8029\n",
      "Epoch 61/150\n",
      "1027/1027 [==============================] - 1s 753us/step - loss: 0.3761 - accuracy: 0.8029 - val_loss: 0.3753 - val_accuracy: 0.8045\n",
      "Epoch 62/150\n",
      "1027/1027 [==============================] - 1s 745us/step - loss: 0.3765 - accuracy: 0.8014 - val_loss: 0.3707 - val_accuracy: 0.8061\n",
      "Epoch 63/150\n",
      "1027/1027 [==============================] - 1s 752us/step - loss: 0.3747 - accuracy: 0.8021 - val_loss: 0.3700 - val_accuracy: 0.8054\n",
      "Epoch 64/150\n",
      "1027/1027 [==============================] - 1s 789us/step - loss: 0.3738 - accuracy: 0.8031 - val_loss: 0.3724 - val_accuracy: 0.8032\n",
      "Epoch 65/150\n",
      "1027/1027 [==============================] - 1s 808us/step - loss: 0.3746 - accuracy: 0.8020 - val_loss: 0.3684 - val_accuracy: 0.8070\n",
      "Epoch 66/150\n",
      "1027/1027 [==============================] - 1s 795us/step - loss: 0.3737 - accuracy: 0.8027 - val_loss: 0.3757 - val_accuracy: 0.8067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x178bc9cb610>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model_dropout = Sequential(\n",
    "    [\n",
    "        Dense(24 ,input_dim = 5, activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(12 , activation='relu'),\n",
    "        Dense(1 , activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "mlp_model_dropout.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "mlp_model_dropout.fit(X_train,y_train,epochs = 150, callbacks=[early_stopping],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22594c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc483a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "0              0.645782  0.937853  0.764884   3363.000000\n",
      "1              0.961196  0.749529  0.842268   6907.000000\n",
      "accuracy       0.811198  0.811198  0.811198      0.811198\n",
      "macro avg      0.803489  0.843691  0.803576  10270.000000\n",
      "weighted avg   0.857911  0.811198  0.816928  10270.000000\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp_model_dropout.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "report = classification_report(y_test,y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66925c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
