from numpy.random import choice as np_choice
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
import numpy as np
import pandas as pd 
from IPython.display import display
from scipy.sparse import csr_matrix
import scipy.sparse as sp
import gensim
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from gensim.models import Word2Vec
import warnings
import pants
import math
import time
import json
import random
import statistics
from numpy import inf
import matplotlib.pyplot as plt
import networkx as nx
warnings.filterwarnings(action = 'ignore')

class document_processing(object):
    
    
    def __init__(self,dataset):
        self.data=pd.read_csv(dataset)
        self.corpus=None
        
      
    def readDataset(self):
        
       
        self.corpus=self.data['ImportedSymbols']
