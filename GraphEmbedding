G=nx.read_edgelist('goodware_tfidf_edgelist.txt',
create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])

model_n2v = Node2Vec(G, walk_length=100, num_walks=80,
p=0.25, q=4, workers=1, use_rejection_sampling=0)
model_n2v.train(window_size = 20, iter = 3)

print(model2_n2v.w2v_model)

with open('tfidf_goodware_graph_embedding.txt', 'w') as f:
    f.write(json.dumps(embeddings))

G=nx.read_edgelist('malware_tfidf_edgelist.txt',
create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])

model2_n2v = Node2Vec(G, walk_length=100, num_walks=80,
p=0.25, q=4, workers=1, use_rejection_sampling=0)
model2_n2v.train(window_size = 20, iter = 3)

with open('tfidf_malware_graph_embedding.txt', 'w') as f:
    f.write(json.dumps(embeddings2))
with open('tfidf_goodware_graph_embedding.txt', 'r') as f:
            embeddings = json.loads(f.read())
with open('tfidf_malware_graph_embedding.txt', 'r') as f:
            embeddings2 = json.loads(f.read())
from sklearn.cluster import AgglomerativeClustering

cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')
cluster.fit_predict(embeddings)
print(cluster.labels_)
plt.scatter(np.array(embeddings)[:, 0], np.array(embeddings)[:, 1], c=cluster.labels_, cmap='rainbow')
from sklearn.cluster import AgglomerativeClustering

cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')
cluster.fit_predict(embeddings)
print(cluster.labels_)
plt.scatter(np.array(embeddings)[:, 0], np.array(embeddings)[:, 1], c=cluster.labels_, cmap='rainbow')
kmeans = KMeans(n_clusters=7, random_state=0).fit(embeddings)
y_kmeans = kmeans.predict(embeddings)
f = plt.figure()
f.set_figwidth(10)
f.set_figheight(10)
plt.scatter(np.array(embeddings)[:, 0], np.array(embeddings)[:, 1], c=y_kmeans, s=50, cmap='viridis')
# centers = kmeans.cluster_centers_
# plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);
kmeans = KMeans(n_clusters=7, random_state=0).fit(embeddings)
y_kmeans = kmeans.predict(embeddings)
f = plt.figure()
f.set_figwidth(10)
f.set_figheight(10)
plt.scatter(np.array(embeddings)[:, 0], np.array(embeddings)[:, 1], c=y_kmeans, s=50, cmap='viridis')
# centers = kmeans.cluster_centers_
# plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);
mix_goodware = [[a*b for a,b in zip(x,y)] for x,y in zip(model.our_tfidf_matrix,embeddings)]
# with open("mix_goodware.txt", 'w') as f:
            
#     f.write(json.dumps(mix_goodware))
mix_malware=[[a*b for a,b in zip(x,y)] for x,y in zip(model2.our_tfidf_matrix,embeddings2)]
# with open("mix_malware.txt", 'w') as f:
            
#     f.write(json.dumps(mix_malware))
with open("malware_antcolony_results.txt", 'r') as f:
            ant_mal = json.loads(f.read())
with open("goodware_antcolony_results.txt", 'r') as f:
            ant_good = json.loads(f.read())
mix_goodware_map={}
mix_malware_map={}

for i in range(len(model.tfidf_instance.vocab)):
    
    for j in range(len(model.tfidf_instance.vocab)):
        
        mix_goodware_map[(model.tfidf_instance.vocab[i],model.tfidf_instance.vocab[j])]=mix_goodware[i][j]
                
for i in range(len(model2.tfidf_instance.vocab)):
            for j in range(len(model2.tfidf_instance.vocab)):
                mix_malware_map[(model2.tfidf_instance.vocab[i],model2.tfidf_instance.vocab[j])]=mix_malware[i][j]
del ant_good
del ant_mal
data=pd.read_csv("brazilian-malware.csv")
corpus=data['ImportedSymbols']
data2=pd.read_csv("goodware.csv")
corpus2=data2['ImportedSymbols']
x=corpus.tolist()
y=corpus2.tolist()
def remove_common(a, b):
  
    for i in a:
        if i in b:
            
            a.remove(i)
            
  
#     print("list1 : ", a)
#     print("list2 : ", b)
  
remove_common(x,y)
print(len(corpus))
print(len(corpus2))
print(len(x))
print(len(y))
corpus=x
predicted_good=[]
predicted_mal=[]
equal=[]
for j in range (len(corpus)):
    sum_mal=0
    sum_good=0
    new_test=corpus[j].split()



    for i in range(len(new_test)-1):


                if(mix_malware_map.get((new_test[i].lower(),new_test[i+1].lower()))!=None):
                    sum_mal+=1
                    


                if(mix_goodware_map.get((new_test[i].lower(),new_test[i+1].lower()))!=None):
                    sum_good+=1
                    
          
            


    if(sum_mal<sum_good):
        predicted_good.append(1)



    elif(sum_mal>sum_good):
        predicted_mal.append(1)

    else:
        equal.append(1)



print("Length of the dataset is equal to " + str(len(corpus)))
print("Instances classified as goodware "+str(len(predicted_good)))
print("Instances classified as malware " + str(len(predicted_mal)))
print("Cant Classify = " +str(len(equal)))
